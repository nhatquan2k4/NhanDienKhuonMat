{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "724df036",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet18 as torchvision_resnet18, ResNet18_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d14fd99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletFaceDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.people = os.listdir(root_dir)\n",
    "        self.image_paths = {p: os.listdir(os.path.join(root_dir, p)) for p in self.people}\n",
    "\n",
    "    def __len__(self):\n",
    "        return 10000\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        person = random.choice(self.people)\n",
    "        img_paths = random.sample(self.image_paths[person], 2)\n",
    "        anchor_path = os.path.join(self.root_dir, person, img_paths[0])\n",
    "        positive_path = os.path.join(self.root_dir, person, img_paths[1])\n",
    "\n",
    "        negative_person = random.choice(self.people)\n",
    "        while negative_person == person:\n",
    "            negative_person = random.choice(self.people)\n",
    "        negative_path = os.path.join(self.root_dir, negative_person, random.choice(self.image_paths[negative_person]))\n",
    "\n",
    "        anchor = Image.open(anchor_path).convert(\"RGB\")\n",
    "        positive = Image.open(positive_path).convert(\"RGB\")\n",
    "        negative = Image.open(negative_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            anchor = self.transform(anchor)\n",
    "            positive = self.transform(positive)\n",
    "            negative = self.transform(negative)\n",
    "\n",
    "        return anchor, positive, negative\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17f075e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a6a7713",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomResNet18(nn.Module):\n",
    "    def __init__(self, num_classes=128):\n",
    "        super(CustomResNet18, self).__init__()\n",
    "        self.inplanes = 64\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(BasicBlock, 64, 2)\n",
    "        self.layer2 = self._make_layer(BasicBlock, 128, 2, stride=2)\n",
    "        self.layer3 = self._make_layer(BasicBlock, 256, 2, stride=2)\n",
    "        self.layer4 = self._make_layer(BasicBlock, 512, 2, stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "        layers = [block(self.inplanes, planes, stride, downsample)]\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return F.normalize(x, p=2, dim=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99803609",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained_weights(custom_model, pretrained_model):\n",
    "    pretrained_dict = pretrained_model.state_dict()\n",
    "    custom_dict = custom_model.state_dict()\n",
    "    matched_dict = {k: v for k, v in pretrained_dict.items()\n",
    "                    if k in custom_dict and v.size() == custom_dict[k].size()}\n",
    "    custom_dict.update(matched_dict)\n",
    "    custom_model.load_state_dict(custom_dict)\n",
    "    print(f\" Loaded {len(matched_dict)} pretrained weights.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec0dcf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TripletNetwork, self).__init__()\n",
    "        self.embedding = CustomResNet18()\n",
    "        pretrained_resnet = torchvision_resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "        load_pretrained_weights(self.embedding, pretrained_resnet)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embedding(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70b2b9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletLoss(nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, anchor, positive, negative):\n",
    "        pos_dist = F.pairwise_distance(anchor, positive, p=2)\n",
    "        neg_dist = F.pairwise_distance(anchor, negative, p=2)\n",
    "        loss = F.relu(pos_dist - neg_dist + self.margin)\n",
    "        return loss.mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f644702",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(anchor, positive, negative):\n",
    "    pos_dist = F.pairwise_distance(anchor, positive, p=2)\n",
    "    neg_dist = F.pairwise_distance(anchor, negative, p=2)\n",
    "    correct = (pos_dist < neg_dist).sum().item()\n",
    "    total = anchor.size(0)\n",
    "    return correct / total\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44420de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for anchor, positive, negative in dataloader:\n",
    "            anchor, positive, negative = anchor.cuda(), positive.cuda(), negative.cuda()\n",
    "            anchor_emb = model(anchor)\n",
    "            positive_emb = model(positive)\n",
    "            negative_emb = model(negative)\n",
    "            loss = criterion(anchor_emb, positive_emb, negative_emb)\n",
    "            acc = compute_accuracy(anchor_emb, positive_emb, negative_emb)\n",
    "\n",
    "            batch_size = anchor.size(0)\n",
    "            total_loss += loss.item() * batch_size\n",
    "            total_correct += acc * batch_size\n",
    "            total_samples += batch_size\n",
    "\n",
    "    avg_loss = total_loss / total_samples\n",
    "    avg_acc = total_correct / total_samples\n",
    "    return avg_loss, avg_acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff2642d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\banhm\\AppData\\Local\\Temp\\ipykernel_17216\\2790138796.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"./final_triplet_resnet18_ss2.pth\"))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image, ImageTk\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from torchvision import transforms, models\n",
    "\n",
    "# === Định nghĩa mô hình TripletNet ===\n",
    "class TripletNet(nn.Module):\n",
    "    def __init__(self, embedding_size=128):\n",
    "        super(TripletNet, self).__init__()\n",
    "        self.embedding = models.resnet18(pretrained=False)\n",
    "        in_features = self.embedding.fc.in_features\n",
    "        self.embedding.fc = nn.Linear(in_features, embedding_size)\n",
    "\n",
    "    def forward_once(self, x):\n",
    "        x = self.embedding(x)\n",
    "        return F.normalize(x, p=2, dim=1)  # chuẩn hóa L2\n",
    "\n",
    "\n",
    "    def forward(self, anchor, positive, negative):\n",
    "        anchor_out = self.forward_once(anchor)\n",
    "        positive_out = self.forward_once(positive)\n",
    "        negative_out = self.forward_once(negative)\n",
    "        return anchor_out, positive_out, negative_out\n",
    "\n",
    "# === Hàm tính embedding cho thư viện ảnh ===\n",
    "def build_gallery_embeddings(model, gallery_dir, transform):\n",
    "    model.eval()\n",
    "    gallery_embeddings = {}\n",
    "    \n",
    "    for person_name in os.listdir(gallery_dir):\n",
    "        person_dir = os.path.join(gallery_dir, person_name)\n",
    "        if not os.path.isdir(person_dir):\n",
    "            continue\n",
    "            \n",
    "        for img_name in os.listdir(person_dir):\n",
    "            img_path = os.path.join(person_dir, img_name)\n",
    "            if not img_name.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                img = Image.open(img_path).convert(\"RGB\")\n",
    "                img_tensor = transform(img).unsqueeze(0).cuda()\n",
    "                with torch.no_grad():\n",
    "                    emb = model.forward_once(img_tensor)\n",
    "                # Key: person_name, Value: embedding\n",
    "\n",
    "                key = f\"{person_name}_{img_name}\"\n",
    "                gallery_embeddings[key] = (person_name, emb)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Lỗi xử lý ảnh {img_path}: {e}\")\n",
    "                \n",
    "    return gallery_embeddings\n",
    "# === Load model & gallery ===\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "model = TripletNet().cuda()\n",
    "model.load_state_dict(torch.load(\"./final_triplet_resnet18_ss2.pth\"))\n",
    "model.eval()\n",
    "\n",
    "gallery_dir = \"./DATA\"\n",
    "gallery_embeddings = build_gallery_embeddings(model, gallery_dir, transform)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "21214eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image, ImageTk\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from torchvision import transforms, models\n",
    "import cv2\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "\n",
    "# === Hàm tính embedding cho tất cả ảnh riêng lẻ ===\n",
    "def build_individual_gallery_embeddings(model, gallery_dir, transform):\n",
    "    model.eval()\n",
    "    gallery_embeddings = {}\n",
    "    \n",
    "    for person_name in os.listdir(gallery_dir):\n",
    "        person_dir = os.path.join(gallery_dir, person_name)\n",
    "        if not os.path.isdir(person_dir):\n",
    "            continue\n",
    "            \n",
    "        for img_name in os.listdir(person_dir):\n",
    "            img_path = os.path.join(person_dir, img_name)\n",
    "            if not img_name.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                img = Image.open(img_path).convert(\"RGB\")\n",
    "                img_tensor = transform(img).unsqueeze(0).cuda()\n",
    "                with torch.no_grad():\n",
    "                    emb = model.forward_once(img_tensor)\n",
    "                # Key: person_name, Value: embedding\n",
    "                key = f\"{person_name}_{img_name}\"\n",
    "                gallery_embeddings[key] = (person_name, emb)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Lỗi xử lý ảnh {img_path}: {e}\")\n",
    "                \n",
    "    return gallery_embeddings\n",
    "\n",
    "# === Hàm nhận diện với tất cả embedding riêng lẻ ===\n",
    "def identify_image(image_path, model, gallery_embeddings, transform, threshold=0.4):\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    img_tensor = transform(img).unsqueeze(0).cuda()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        query_emb = model.forward_once(img_tensor)\n",
    "    \n",
    "    min_dist = float(\"inf\")\n",
    "    identity = \"unknown\"\n",
    "    matched_image = \"\"\n",
    "    \n",
    "    for key, (person_name, emb) in gallery_embeddings.items():\n",
    "        dist = F.pairwise_distance(query_emb, emb)\n",
    "        if dist.item() < min_dist:\n",
    "            min_dist = dist.item()\n",
    "            identity = person_name\n",
    "            matched_image = key\n",
    "    \n",
    "    if min_dist >= threshold:\n",
    "        identity = \"unknown\"\n",
    "        matched_image = \"\"\n",
    "    \n",
    "    return identity, min_dist, matched_image\n",
    "\n",
    "# === Phương pháp kết hợp (Voting) ===\n",
    "def identify_image_voting(image_path, model, gallery_embeddings, transform, threshold=0.4, top_k=5):\n",
    "    \"\"\"\n",
    "    Lấy top-k ảnh gần nhất và vote cho người xuất hiện nhiều nhất\n",
    "    \"\"\"\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    img_tensor = transform(img).unsqueeze(0).cuda()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        query_emb = model.forward_once(img_tensor)\n",
    "    \n",
    "    # Tính khoảng cách với tất cả\n",
    "    distances = []\n",
    "    for key, (person_name, emb) in gallery_embeddings.items():\n",
    "        dist = F.pairwise_distance(query_emb, emb).item()\n",
    "        distances.append((dist, person_name, key))\n",
    "    \n",
    "    # Sắp xếp theo khoảng cách\n",
    "    distances.sort(key=lambda x: x[0])\n",
    "    \n",
    "    # Lấy top-k và vote\n",
    "    votes = {}\n",
    "    for i in range(min(top_k, len(distances))):\n",
    "        dist, person_name, key = distances[i]\n",
    "        if dist < threshold:  # Chỉ vote cho những cái đủ gần\n",
    "            votes[person_name] = votes.get(person_name, 0) + 1\n",
    "    \n",
    "    if not votes:\n",
    "        return \"unknown\", distances[0][0] if distances else float(\"inf\"), \"\"\n",
    "    \n",
    "    # Người có nhiều vote nhất\n",
    "    identity = max(votes.keys(), key=lambda x: votes[x])\n",
    "    min_dist = distances[0][0]  # Khoảng cách ngắn nhất\n",
    "    \n",
    "    return identity, min_dist, distances[0][2]\n",
    "\n",
    "# === Hàm nhận diện khuôn mặt từ frame camera ===\n",
    "def identify_frame(frame, model, gallery_embeddings, transform, threshold=0.7):\n",
    "    # Chuyển frame OpenCV (BGR) sang RGB\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    # Tìm vị trí khuôn mặt\n",
    "    face_locations = face_recognition.face_locations(rgb_frame)\n",
    "    \n",
    "    results = []\n",
    "    for (top, right, bottom, left) in face_locations:\n",
    "        # Cắt vùng khuôn mặt\n",
    "        face_image = rgb_frame[top:bottom, left:right]\n",
    "        face_pil = Image.fromarray(face_image).convert(\"RGB\")\n",
    "        face_tensor = transform(face_pil).unsqueeze(0).cuda()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            query_emb = model.forward_once(face_tensor)\n",
    "        \n",
    "        min_dist = float(\"inf\")\n",
    "        identity = \"unknown\"\n",
    "        \n",
    "        for key, (person_name, emb) in gallery_embeddings.items():\n",
    "            dist = F.pairwise_distance(query_emb, emb)\n",
    "            if dist.item() < min_dist:\n",
    "                min_dist = dist.item()\n",
    "                identity = person_name\n",
    "        \n",
    "        if min_dist >= threshold:\n",
    "            identity = \"unknown\"\n",
    "        \n",
    "        results.append((identity, min_dist, (top, right, bottom, left)))\n",
    "    \n",
    "    return rgb_frame, face_locations, results\n",
    "\n",
    "# === Hàm hiển thị frame với khuôn mặt và nhãn ===\n",
    "def display_frame(frame, face_locations, results):\n",
    "    for (top, right, bottom, left), (identity, dist, _) in zip(face_locations, results):\n",
    "        # Vẽ hình chữ nhật quanh khuôn mặt\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "        # Hiển thị nhãn trên hình chữ nhật\n",
    "        label = f\"{identity} ({dist:.3f})\"\n",
    "        cv2.putText(frame, label, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "    \n",
    "    # Chuyển frame sang định dạng PIL để hiển thị trên Tkinter\n",
    "    frame_pil = Image.fromarray(frame)\n",
    "    frame_pil = frame_pil.resize((500, 500), Image.Resampling.LANCZOS)\n",
    "    frame_tk = ImageTk.PhotoImage(frame_pil)\n",
    "    image_label.config(image=frame_tk)\n",
    "    image_label.image = frame_tk\n",
    "    # Cập nhật kết quả nhận diện\n",
    "    if results:\n",
    "        identity, dist, _ = results[0]  # Hiển thị kết quả của khuôn mặt đầu tiên\n",
    "        result_text.set(f\"Dự đoán: {identity}\\nKhoảng cách: {dist:.3f}\")\n",
    "    else:\n",
    "        result_text.set(\"Không phát hiện khuôn mặt\")\n",
    "\n",
    "# === Hàm bật camera và nhận diện thời gian thực ===\n",
    "def start_camera():\n",
    "    global cap, is_camera_running\n",
    "    if is_camera_running:\n",
    "        return\n",
    "    \n",
    "    is_camera_running = True\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        result_text.set(\"Lỗi: Không thể mở camera\")\n",
    "        is_camera_running = False\n",
    "        return\n",
    "    \n",
    "    def update_frame():\n",
    "        if not is_camera_running:\n",
    "            return\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            # Nhận diện khuôn mặt và vẽ hình chữ nhật\n",
    "            rgb_frame, face_locations, results = identify_frame(frame, model, gallery_embeddings, transform)\n",
    "            # Hiển thị frame\n",
    "            display_frame(rgb_frame, face_locations, results)\n",
    "            # Lặp lại để cập nhật frame\n",
    "            root.after(50, update_frame)\n",
    "        else:\n",
    "            result_text.set(\"Lỗi: Không thể đọc frame từ camera\")\n",
    "            stop_camera()\n",
    "    \n",
    "    update_frame()\n",
    "\n",
    "# === Hàm dừng camera ===\n",
    "def stop_camera():\n",
    "    global cap, is_camera_running\n",
    "    if is_camera_running:\n",
    "        is_camera_running = False\n",
    "        if cap is not None:\n",
    "            cap.release()\n",
    "        image_label.config(image=\"\")\n",
    "        image_label.image = None\n",
    "        result_text.set(\"Camera đã dừng\")\n",
    "\n",
    "# === Giao diện chính ===\n",
    "def upload_and_identify():\n",
    "    file_path = filedialog.askopenfilename(filetypes=[(\"Image files\", \"*.jpg *.jpeg *.png\")])\n",
    "    if not file_path:\n",
    "        return\n",
    "\n",
    "    img = Image.open(file_path).convert(\"RGB\")\n",
    "    img.thumbnail((300, 300))\n",
    "    img_tk = ImageTk.PhotoImage(img)\n",
    "    image_label.config(image=img_tk)\n",
    "    image_label.image = img_tk\n",
    "\n",
    "    identity, dist, matched_image = identify_image(file_path, model, gallery_embeddings, transform)\n",
    "    filename = os.path.basename(file_path)\n",
    "    image_name = os.path.splitext(filename)[0]\n",
    "\n",
    "    if image_name.lower().startswith(identity.lower()):\n",
    "        result_label.config(fg=\"green\")\n",
    "    else:\n",
    "        result_label.config(fg=\"red\")\n",
    "\n",
    "    result_text.set(\n",
    "        f\"Tên ảnh: {image_name}\\n\"\n",
    "        f\"Dự đoán: {identity}\\n\"\n",
    "\n",
    "    )\n",
    "\n",
    "# def batch_test():\n",
    "#     folder_path = filedialog.askdirectory(title=\"Chọn thư mục chứa ảnh để kiểm tra\")\n",
    "#     if not folder_path:\n",
    "#         return\n",
    "\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "#     log_lines = []\n",
    "\n",
    "#     for filename in os.listdir(folder_path):\n",
    "#         if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "#             file_path = os.path.join(folder_path, filename)\n",
    "#             image_name = os.path.splitext(filename)[0]\n",
    "#             identity, dist, matched_image = identify_image(file_path, model, gallery_embeddings, transform)\n",
    "\n",
    "#             if image_name.lower().startswith(identity.lower()):\n",
    "#                 correctness = \"Đúng\"\n",
    "#                 correct += 1\n",
    "#             else:\n",
    "#                 correctness = \"Sai\"\n",
    "#             total += 1\n",
    "#             log_lines.append(f\"{filename} --> Dự đoán: {identity}, Kết quả: {correctness}\")\n",
    "\n",
    "#     summary = f\"\\nTổng: {total} ảnh | Đúng: {correct} | Sai: {total - correct}\"\n",
    "#     log_lines.append(summary)\n",
    "\n",
    "#     result_text.set(summary)\n",
    "#     print(\"\\n\".join(log_lines))\n",
    "\n",
    "# === Khởi tạo giao diện ===\n",
    "root = tk.Tk()\n",
    "root.title(\"Hệ thống Nhận diện Khuôn mặt\")\n",
    "root.geometry(\"1200x700\")\n",
    "root.configure(bg=\"#e6ecf0\") \n",
    "\n",
    "# Tiêu đề\n",
    "title = tk.Label(root, text=\"HỆ THỐNG NHẬN DIỆN KHUÔN MẶT\", font=(\"Helvetica\", 20, \"bold\"), bg=\"#e6ecf0\", fg=\"#2c3e50\")\n",
    "title.pack(pady=20)\n",
    "\n",
    "# Frame chứa các nút\n",
    "button_frame = tk.Frame(root, bg=\"#e6ecf0\")\n",
    "button_frame.pack(pady=10)\n",
    "\n",
    "# Các nút bấm\n",
    "upload_btn = tk.Button(\n",
    "    button_frame, \n",
    "    text=\"Chọn ảnh để nhận diện\", \n",
    "    font=(\"Helvetica\", 14), \n",
    "    bg=\"#3498db\",  # Màu xanh dương nhẹ\n",
    "    fg=\"white\", \n",
    "    width=20, \n",
    "    padx=10, \n",
    "    pady=8, \n",
    "    relief=\"flat\",\n",
    "    activebackground=\"#2980b9\",\n",
    "    command=upload_and_identify\n",
    ")\n",
    "upload_btn.pack(side=\"left\", padx=10)\n",
    "\n",
    "camera_btn = tk.Button(\n",
    "    button_frame, \n",
    "    text=\"Bật Camera\", \n",
    "    font=(\"Helvetica\", 14), \n",
    "    bg=\"#1abc9c\",  # Màu xanh ngọc\n",
    "    fg=\"white\", \n",
    "    width=20, \n",
    "    padx=10, \n",
    "    pady=8, \n",
    "    relief=\"flat\",\n",
    "    activebackground=\"#16a085\",\n",
    "    command=start_camera\n",
    ")\n",
    "camera_btn.pack(side=\"left\", padx=10)\n",
    "\n",
    "stop_camera_btn = tk.Button(\n",
    "    button_frame, \n",
    "    text=\"Dừng Camera\", \n",
    "    font=(\"Helvetica\", 14), \n",
    "    bg=\"#e74c3c\",  # Màu đỏ nhạt\n",
    "    fg=\"white\", \n",
    "    width=20, \n",
    "    padx=10, \n",
    "    pady=8, \n",
    "    relief=\"flat\",\n",
    "    activebackground=\"#c0392b\",\n",
    "    command=stop_camera\n",
    ")\n",
    "stop_camera_btn.pack(side=\"left\", padx=10)\n",
    "\n",
    "# Frame hiển thị ảnh\n",
    "frame_image = tk.Frame(root, width=500, height=500, bg=\"white\", bd=3, relief=\"ridge\")\n",
    "frame_image.pack(pady=20)\n",
    "image_label = tk.Label(frame_image, bg=\"white\")\n",
    "image_label.pack()\n",
    "\n",
    "# Kết quả nhận diện\n",
    "result_text = tk.StringVar()\n",
    "result_label = tk.Label(root, textvariable=result_text, font=(\"Helvetica\", 16), bg=\"#e6ecf0\", fg=\"#2c3e50\", justify=\"center\")\n",
    "result_label.pack(pady=20)\n",
    "\n",
    "# Nút kiểm tra hàng loạt\n",
    "# batch_btn = tk.Button(\n",
    "#     root, \n",
    "#     text=\"Kiểm tra cả thư mục ảnh\", \n",
    "#     font=(\"Helvetica\", 14), \n",
    "#     bg=\"#2ecc71\",  # Màu xanh lá\n",
    "#     fg=\"white\", \n",
    "#     width=25, \n",
    "#     padx=10, \n",
    "#     pady=8, \n",
    "#     relief=\"flat\",\n",
    "#     activebackground=\"#27ae60\",\n",
    "#     command=batch_test\n",
    "# )\n",
    "# batch_btn.pack(pady=10)\n",
    "\n",
    "cap = None\n",
    "is_camera_running = False\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdaa07f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NQ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
